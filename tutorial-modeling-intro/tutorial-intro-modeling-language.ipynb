{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to modeling in Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces Gen's built-in modeling language, and illustrates probabilistic inference in Gen using a simple generic inference algorithm.\n",
    "\n",
    "This tutorial will guide you through how to:\n",
    "\n",
    "- Express a probabilistic model as a generative function in Gen\n",
    "\n",
    "- Obtain the trace of a generative function, and inspect and visualize it the trace.\n",
    "\n",
    "- Write a simple inference program based on a generic importance sampling inference algorithm.\n",
    "\n",
    "- Interpret the output of the inference program, and the effect of amount of computation on accuracy of inferences.\n",
    "\n",
    "The tutorial also illustrates different types of modeling flexibility afforded by the built-in modeling language. You will:\n",
    "\n",
    "- Write a probabilistic model that uses a stochastic if-else branch to infer which model of two models best explains a data set.\n",
    "\n",
    "- Write a probabilistic model that uses an unbounded number of parameters using recursion.\n",
    "\n",
    "- Write a probabilistic model that invokes general-purpose black-box code.\n",
    "\n",
    "Note that this tutorial does not cover *inference programming*, in which users implement inference algorithms that are specialized to their probabilistic model. Inference programming is important for getting accurate inferences efficiently, and will be covered in later tutorials. Also, this tutorial does not exhaustively cover all features of the modeling language -- there are also various features and extensions that provide improved performance that are not covered here.\n",
    "\n",
    "### Outline\n",
    "\n",
    "1. [Julia, Gen, and this Jupyter notebook](#julia-gen-jupyter)\n",
    "\n",
    "2. [Writing a probabilistic model as a generative function](#writing-model)\n",
    "\n",
    "3. [Doing Bayesian inference](#doing-inference)\n",
    "\n",
    "4. [Predicting new data](#predicting-data)\n",
    "\n",
    "5. [Calling other generative functions](#calling-functions)\n",
    "\n",
    "6. [Modeling with an infinite discrete hypothesis space](#infinite-space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Julia, Gen, and this Jupyter notebook  <a name=\"julia-gen-jupyter\"></a>\n",
    "\n",
    "Gen is a package for the Julia language. The package can be loaded with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gen programs typically consist of a combination of (i) probabilistic models written in modeling languages and (ii) inference programs written in regular Julia code. Gen provides a built-in modeling language that is itself based on Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses a Jupyter notebook. All cells in the notebook are regular Julia cells. Throughout the tutorial, we will use  that we use semicolons at the end of some cells so that the value of a cell is not printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 1 + 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the [PyPlot](https://github.com/JuliaPy/PyPlot.jl) Julia package for plotting. PyPlot wraps the matplotlib Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will make use of Julia symbols. Note that a Julia symbol is different from a Julia string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(:foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(\"foo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing a probabilistic model as a generative function  <a name=\"writing-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic models represented in Gen as *generative functions*. The simplest way to construct a generative function is by using the built-in modeling DSL. Generative functions written in the built-in modeling DSL are based on Julia function definition syntax, but are prefixed with the `@gen` keyword. The generative function below represents a probabilistic model of a line in the x-y plane, and values of the y-coordinates associated with a given set of x-coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function line_model(xs::Vector{Float64})\n",
    "    n = length(xs)\n",
    "    slope = @addr(normal(0, 1), :slope)\n",
    "    intercept = @addr(normal(0, 2), :intercept)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(slope * x + intercept, 0.1), (:y, i))\n",
    "    end\n",
    "    return n\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function takes as an argument a vector of x-coordinates. We create one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [-5., -4., -3., -.2, -1., 0., 1., 2., 3., 4., 5.];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function then samples a random choice representing the slope of a line from a normal distribution with mean 0 and standard deviation 1, and a random choice representing the intercept of a line from a normal distribution with mean 0 and standard deviation 2. In Bayesian statistics terms, these distributions are the *prior distributions* of the slope and intercept respectively. Then, the function samples values for the y-coordinates corresponding to each of the provided x-coordinates Each random choice has a unique *address*. A random choice is assigned an address using the `@addr` keyword. Addresses can be any Julia value. In this program, there are two types of addresses used -- Julia symbols and tuples of symbols and integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "### Exercise\n",
    "List the addresses of all random choices made when applying `line_model` to the vector `xs` defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":slope, :intercept, (:y, 1), ..., (:y, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "### Exercise\n",
    "\n",
    "Write a generative function that uses the same address twice. Run it to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function foo()\n",
    "    @addr(normal(0, 1), :x)\n",
    "    @addr(normal(0, 1), :x)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generative function returns the number of data points. We can run the function like we run a regular Julia function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = line_model(xs)\n",
    "println(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the random choices made by this generative function that are most important. The random choices are not included in the return value. They are however, included in the *trace* of the generative function. We can run the generative function and obtain its trace using the a method from the Gen API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trace, _) = Gen.initialize(line_model, (xs,));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes the function to be executed, and a tuple of arguments to the function, and returns a trace and a second value that we will not be using in this tutorial. When we print the trace, we see that it is a complex data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace contains various data about the execution. In particular, in contains the arguments on which the function was run, which are available with an API method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen.get_args(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace also contains the value of the random choices, stored in map from addresses to their values. This map is also available through an API method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(Gen.get_assmt(trace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return value is also recorded in the trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(Gen.get_retval(trace));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the probabilistic behavior of a generative function, it is helpful to be able to visualize the trace of a generative function. Below, we define a function that uses PyPlot to render a trace of the generative function above. The rendering shows the x-y data points and the line that is represented by the slope and intercept choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function render_trace(trace; show_data=true)\n",
    "    xs = get_args(trace)[1]\n",
    "    assmt = get_assmt(trace)\n",
    "    if show_data\n",
    "        ys = [assmt[(:y, i)] for i=1:length(xs)]\n",
    "        scatter(xs, ys, c=\"black\")\n",
    "    end\n",
    "    slope = assmt[:slope]\n",
    "    intercept = assmt[:intercept]\n",
    "    xmin = minimum(xs)\n",
    "    xmax = maximum(xs)\n",
    "    plot([xmin, xmax], slope *  [xmin, xmax] .+ intercept, color=\"black\", alpha=0.5)\n",
    "    ax = gca()\n",
    "    ax[:set_xlim]((xmin, xmax))\n",
    "    ax[:set_ylim]((xmin, xmax))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(3,3))\n",
    "render_trace(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because a generative function is stochastic, we need to visualize many runs in order to understand its behavoir. The cell below will allow us to render a grid of traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function grid(renderer, traces; ncols=6, nrows=3)\n",
    "    figure(figsize=(16, 8))\n",
    "    for (i, trace) in enumerate(traces)\n",
    "        subplot(nrows, ncols, i)\n",
    "        renderer(trace)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we generate several traces and render them in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [initialize(line_model, (xs,))[1] for _=1:12]\n",
    "grid(render_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "### Exercise\n",
    "\n",
    "Write a model that generates a sine wave of unknown phase, period and amplitude, and then generates y-coordinates from a given vector of x-coordinates by adding noise to the value of the wave at each x-coordinate.\n",
    "Use a Gamma distribution  (see [`Gen.gamma`](https://probcomp.github.io/Gen/dev/ref/distributions/#Gen.gamma)). for the prior distributions on the period and amplitude, and a uniform distribution for the phase (see [`Gen.uniform`](https://probcomp.github.io/Gen/dev/ref/distributions/#Gen.uniform)). Write a function that renders the trace by showing the data set and the sine wave. Visualize a grid of traces and discuss the distribution. Try tweaking the parameters of each of the prior distributions and seeing how the behavior changes.\n",
    "\n",
    "Hint: There should be three random choices corresponding to the period, amplitude, and phase, and then N random choices, one for each y-coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function sine_model(xs::Vector{Float64})\n",
    "    n = length(xs)\n",
    "    period = @addr(gamma(1, 1), :period)\n",
    "    amplitude = @addr(gamma(1, 1), :amp)\n",
    "    phase = @addr(uniform(0, 2*pi), :phase)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(amplitude * sin(x * (2 * pi / period) + phase), 0.1), (:y, i))\n",
    "    end\n",
    "    return n\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function render_sine_trace(trace; show_data=true)\n",
    "    xs = get_args(trace)[1]\n",
    "    assmt = get_assmt(trace)\n",
    "    if show_data\n",
    "        ys = [assmt[(:y, i)] for i=1:length(xs)]\n",
    "        scatter(xs, ys, c=\"black\")\n",
    "    end\n",
    "    period = assmt[:period]\n",
    "    amp = assmt[:amp]\n",
    "    phase = assmt[:phase]\n",
    "    xmin = minimum(xs)\n",
    "    xmax = maximum(xs)\n",
    "    test_xs = collect(range(-5, stop=5, length=100))\n",
    "    plot(test_xs, amp * sin.(test_xs * (2 * pi / period) .+ phase), color=\"black\", alpha=0.5)\n",
    "    ax = gca()\n",
    "    ax[:set_xlim]((xmin, xmax))\n",
    "    ax[:set_ylim]((xmin, xmax))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traces = [initialize(sine_model, (xs,))[1] for _=1:12];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16, 8))\n",
    "for (i, trace) in enumerate(traces)\n",
    "    subplot(3, 6, i)\n",
    "    render_sine_trace(trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Doing Bayesian inference  <a name=\"doing-inference\"></a>\n",
    "\n",
    "We now will provide a data set of y-coordinates and try to draw inferences about the process that generated the data. We begin with the following data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [6.75003, 6.1568, 4.26414, 1.84894, 3.09686, 1.94026, 1.36411, -0.83959, -0.976, -1.93363, -2.91303];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(3,3))\n",
    "scatter(xs, ys, color=\"black\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by assuming that the line model was responsible for generatin the data, and inferring values of the slope and intercept that explain the data.\n",
    "\n",
    "To do this, we write a simple *inference program* that takes the model we are assuming, the data set, and the amount of computation to perform, and returns a trace of the function that is approximately sampled from the posterior distribution on traces of the function, given the observed data. This inference program is based on a Gen API method `importance_resampling`. Don't worry about the internals of this inference program yet. We will discuss inference programming in later tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function do_inference(model, xs, ys, amount_of_computation)\n",
    "    observations = Gen.DynamicAssignment()\n",
    "    for (i, y) in enumerate(ys)\n",
    "        observations[(:y, i)] = y\n",
    "    end\n",
    "    (trace, _) = Gen.importance_resampling(model, (xs,), observations, amount_of_computation);\n",
    "    return trace\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the inference program and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = do_inference(line_model, xs, ys, 100)\n",
    "figure(figsize=(3,3))\n",
    "render_trace(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize many samples in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [do_inference(line_model, xs, ys, 100) for _=1:10];\n",
    "grid(render_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in this case we can get a better sense for the variability in the posterior distribution by overlaying the traces. Each trace is going to have the same observed data points, so we only plot those once, based on the values in the first trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function overlay(renderer, traces; same_data=true, args...)\n",
    "    renderer(traces[1], show_data=true, args...)\n",
    "    for i=2:length(traces)\n",
    "        renderer(traces[i], show_data=!same_data, args...)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [do_inference(line_model, xs, ys, 100) for _=1:10];\n",
    "figure(figsize=(3,3))\n",
    "overlay(render_trace, traces);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Exercise\n",
    "\n",
    "The results above were obtained for `amount_of_computation = 100`. Run the algorithm with this value set to `1`, `10`, and `1000`, etc.  Which value seems like a good tradeoff between accuracy and running time? Discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [do_inference(line_model, xs, ys, 1) for _=1:10];\n",
    "figure(figsize=(3, 3));\n",
    "overlay(render_trace, traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [do_inference(line_model, xs, ys, 10) for _=1:10];\n",
    "figure(figsize=(3, 3));\n",
    "overlay(render_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "### Exercise\n",
    "Consider the following data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys_sine = [2.89, 2.22, -0.612, -0.522, -2.65, -0.133, 2.70, 2.77, 0.425, -2.11, -2.76];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(3, 3));\n",
    "scatter(xs, ys_sine, color=\"black\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an inference program that generates traces of the sine wave model that explain this data set. Visualize the resulting distribution of traces. Experiment with a `gamma(1, 1)` and `gamma(5, 1)` prior on the period. Read about the Gamma distribution at https://en.wikipedia.org/wiki/Gamma_distribution. Discuss the results of inference? Do they make sense? How much computation did you need to get good results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traces = [do_inference(sine_model, xs, ys_sine, 1000) for _=1:10];\n",
    "figure(figsize=(3,3))\n",
    "overlay(render_sine_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting, because any multiple of the \"true period\" also can explain the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function sine_model_2(xs::Vector{Float64})\n",
    "    period = @addr(gamma(5, 1), :period)\n",
    "    amplitude = @addr(gamma(1, 1), :amp)\n",
    "    phase = @addr(uniform(0, 2*pi), :phase)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(amplitude * sin(x * (2 * pi / period) + phase), 0.1), (:y, i))\n",
    "    end\n",
    "    return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [do_inference(sine_model_2, xs, ys_sine, 1000) for _=1:10];\n",
    "figure(figsize=(3,3))\n",
    "overlay(render_sine_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we reduce the prior probability of very high frequencies, we can get the posterior to concentrate on the \"right\" period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicting new data  <a name=\"predicting-data\"></a>\n",
    "\n",
    "By providing a third argument to `Gen.initialize`, it is possible to run a generatiev function with the values of certain random choices constrained to given values. The third argument an assignment. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = Gen.DynamicAssignment()\n",
    "constraints[:slope] = 0.\n",
    "constraints[:intercept] = 0.\n",
    "(trace, _) = Gen.initialize(line_model, (xs,), constraints)\n",
    "figure(figsize=(3,3))\n",
    "render_trace(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the random choices corresponding to the y-coordinates are still made randomly. Run the cell above a few times to verify this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the ability to run constrained executions of a generative function to predict the value of the y-coordinates at new x-coordinates by running new executions of the model generative function in which the random choices corresponding to the parameters have been constrained to their inferred values.  We have provided a function below that takes a trace, and a vector of new x-coordinates, and returns a vector of predicted y-coordinates corresponding to the x-coordinates in `new_xs`. We have designed this function to work with multiple models, so the set of parameter addresses is an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predict_new_data(model, trace, new_xs::Vector{Float64}, param_addrs)\n",
    "    constraints = Gen.DynamicAssignment()\n",
    "    assmt = Gen.get_assmt(trace)\n",
    "    for addr in param_addrs\n",
    "        if Gen.has_value(assmt, addr)\n",
    "            constraints[addr] = assmt[addr]\n",
    "        end\n",
    "    end\n",
    "    (new_trace, _) = Gen.initialize(model, (new_xs,), constraints)\n",
    "    new_assmt = Gen.get_assmt(new_trace)\n",
    "    ys = [new_assmt[(:y, i)] for i=1:length(new_xs)]\n",
    "    return ys\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines a function that first performs inference on an observed data set `(xs, ys)`, and then runs `predict_new_data` to generate predicted y-coordinates. It repeats this process `num_traces` times, and returns a vector of the resulting y-coordinate vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function infer_and_predict(model, xs, ys, new_xs, param_addrs, num_traces, amount_of_computation)\n",
    "    pred_ys = []\n",
    "    for i=1:num_traces\n",
    "        trace = do_inference(model, xs, ys, amount_of_computation)\n",
    "        push!(pred_ys, predict_new_data(model, trace, new_xs, param_addrs))\n",
    "    end\n",
    "    pred_ys\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a cell that plots the observed data set `(xs, ys)` as red dots, and the predicted data as small black dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function plot_predictions(xs, ys, new_xs, pred_ys)\n",
    "    scatter(xs, ys, color=\"red\")\n",
    "    for pred_ys_single in pred_ys\n",
    "        scatter(new_xs, pred_ys_single, color=\"black\", s=1, alpha=0.3)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the original dataset for the line model. The x-coordinates span the interval -5 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(3,3))\n",
    "scatter(xs, ys, color=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the inferred values of the parameters to predict y-coordinates for x-coordinates in the interval 5 to 10 from which data was not observed. We will also predict new data within the interval -5 to 5, and we will compare this data to the original observed data. Predicting new data from inferred parameters, and comparing this new data to the observed data is the core idea behind *posterior predictive checking*. This tutorial does not intend to give a rigorous overview behind techniques for checking the quality of a model, but intends to give high-level intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_xs = collect(range(-5, stop=10, length=100));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate and plot the predicted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ys = infer_and_predict(line_model, xs, ys, new_xs, [:slope, :intercept], 20, 1000)\n",
    "figure(figsize=(3,3))\n",
    "plot_predictions(xs, ys, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look reasonable, both within the interval of observed data and in the extrapolated predictions on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the same experiment run with following data set, which has significantly more noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys_noisy = [5.092, 4.781, 2.46815, 1.23047, 0.903318, 1.11819, 2.10808, 1.09198, 0.0203789, -2.05068, 2.66031];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_ys = infer_and_predict(line_model, xs, ys_noisy, new_xs, [:slope, :intercept], 20, 1000)\n",
    "figure(figsize=(3,3))\n",
    "plot_predictions(xs, ys_noisy, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the generated data is less noisy than the observed data in the regime where data was observed, and it looks like the forecasted data is too overconfident. This is a sign that our model is mis-specified. In our case, this is because we have assumed that the noise has value 0.1. However, the actual noise in the data appears to be much larger. We can correct this by making the noise a random choice as well and inferring its value along with the other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first write a new version of the line model that samples a random choice for the noise from a `gamma(1, 1)` prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function line_model_2(xs::Vector{Float64})\n",
    "    n = length(xs)\n",
    "    slope = @addr(normal(0, 1), :slope)\n",
    "    intercept = @addr(normal(0, 2), :intercept)\n",
    "    noise = @addr(gamma(1, 1), :noise)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(slope * x + intercept, noise), (:y, i))\n",
    "    end\n",
    "    return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we compare the predictions using inference the unmodified and modified model on the `ys` data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "pred_ys = infer_and_predict(line_model, xs, ys, new_xs, [:slope, :intercept], 20, 1000)\n",
    "plot_predictions(xs, ys, new_xs, pred_ys)\n",
    "subplot(1, 2, 2)\n",
    "pred_ys = infer_and_predict(line_model_2, xs, ys, new_xs, [:slope, :intercept, :noise], 20, 10000)\n",
    "plot_predictions(xs, ys, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is more uncertainty in the predictions made using the modified model.\n",
    "\n",
    "We also compare the predictions using inference the unmodified and modified model on the `ys_noisy` data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "pred_ys = infer_and_predict(line_model, xs, ys_noisy, new_xs, [:slope, :intercept], 20, 1000)\n",
    "plot_predictions(xs, ys_noisy, new_xs, pred_ys)\n",
    "subplot(1, 2, 2)\n",
    "pred_ys = infer_and_predict(line_model_2, xs, ys_noisy, new_xs, [:slope, :intercept, :noise], 20, 10000)\n",
    "plot_predictions(xs, ys_noisy, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that while the unmodified model was very overconfident, the modified model has an appropriate level of uncertainty, while still capturing the general negative trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "### Exercise\n",
    "\n",
    "Write a modified version the sine model that makes noise into a random choice. Compare the predicted data with the observed data `infer_and_predict` and `plot_predictions` for the unmodified and modified model, and for the `ys_sine` and `ys_noisy` datasets. Discuss the results. Experiment with the amount of inference computation used. The amount of inference computation will need to be higher for the model with the noise random choice. We have provided you with starter code."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@gen function sine_model_3(xs::Vector{Float64})\n",
    "    <fill in code here>\n",
    "    return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "pred_ys = infer_and_predict(sine_model_2, xs, ys_sine, new_xs, <fill in code here>, 20, <fill in code here>)\n",
    "plot_predictions(xs, ys_sine, new_xs, pred_ys)\n",
    "subplot(1, 2, 2)\n",
    "pred_ys = infer_and_predict(sine_model_3, xs, ys_sine, new_xs, <fill in code here>, 20, <fill in code here>)\n",
    "plot_predictions(xs, ys_sine, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "pred_ys = infer_and_predict(sine_model_2, xs, ys_noisy, new_xs, <fill in code here>, 20, <fill in code here>)\n",
    "plot_predictions(xs, ys_noisy, new_xs, pred_ys)\n",
    "subplot(1, 2, 2)\n",
    "pred_ys = infer_and_predict(sine_model_3, xs, ys_noisy, new_xs, <fill in code here>, 20, <fill in code here>)\n",
    "plot_predictions(xs, ys_noisy, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function sine_model_3(xs::Vector{Float64})\n",
    "    period = @addr(gamma(5, 1), :period)\n",
    "    amplitude = @addr(gamma(1, 1), :amp)\n",
    "    phase = @addr(uniform(0, 2*pi), :phase)\n",
    "    noise = @addr(gamma(1, 1), :noise)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(amplitude * sin(x * (2 * pi / period) + phase), noise), (:y, i))\n",
    "    end\n",
    "    return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "pred_ys = infer_and_predict(sine_model_2, xs, ys_sine, new_xs, [:period, :amplitude, :phase], 20, 10000)\n",
    "plot_predictions(xs, ys_sine, new_xs, pred_ys)\n",
    "subplot(1, 2, 2)\n",
    "pred_ys = infer_and_predict(sine_model_3, xs, ys_sine, new_xs, [:period, :amplitude, :phase, :noise], 20, 50000)\n",
    "plot_predictions(xs, ys_sine, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "pred_ys = infer_and_predict(sine_model_2, xs, ys_noisy, new_xs, [:period, :amplitude, :phase], 20, 10000)\n",
    "plot_predictions(xs, ys_noisy, new_xs, pred_ys)\n",
    "subplot(1, 2, 2)\n",
    "pred_ys = infer_and_predict(sine_model_3, xs, ys_noisy, new_xs, [:period, :amplitude, :phase, :noise], 20, 50000)\n",
    "plot_predictions(xs, ys_noisy, new_xs, pred_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calling other generative functions  <a name=\"calling-functions\"></a>\n",
    "\n",
    "In addition to making random choices, generative functions can invoke other generative functions. To illustrate this, we will write a probabilistic model that combines the line model and the sine model. This model is able to explain data using either model, and which model is chosen will depend on the data. This is called *model selection*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generative function can invoke another generative function in two ways -- using `@splice` or using `@addr`. When invoking using `@splice`, the random choices of the callee function are placed in the same address namespace as the caller's random choices. When using `@addr(<call>, <addr>)`, the random choices of the callee are placed under the namespace `<addr>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function foo()\n",
    "    @addr(normal(0, 1), :y)\n",
    "end\n",
    "\n",
    "@gen function bar_splice()\n",
    "    @addr(bernoulli(0.5), :x)\n",
    "    @splice(foo())\n",
    "end\n",
    "\n",
    "@gen function bar_addr()\n",
    "    @addr(bernoulli(0.5), :x)\n",
    "    @addr(foo(), :z)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first show the addresses sampled by `bar_splice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trace, ) = initialize(bar_splice, ())\n",
    "println(get_assmt(trace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the addresses sampled by `bar_addr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trace, ) = initialize(bar_addr, ())\n",
    "println(get_assmt(trace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `@addr` instead of `@splice` can help avoid address collisions for complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we write a generative function that combies the line and sine models. It makes a Bernoulli random choice (e.g. a coin flip that returns true or false) that determines which of the two models will generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function combined_model(xs::Vector{Float64})\n",
    "    if @addr(bernoulli(0.5), :is_line)\n",
    "        @splice(line_model_2(xs))\n",
    "    else\n",
    "        @splice(sine_model_3(xs))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also write a visualization for a trace of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function render_combined(trace; show_data=true)\n",
    "    assmt = get_assmt(trace)\n",
    "    if assmt[:is_line]\n",
    "        render_trace(trace, show_data=show_data)\n",
    "    else\n",
    "        render_sine_trace(trace, show_data=show_data)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize some traces, and see that sometimes it samples linear data and other times sinusoidal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [initialize(combined_model, (xs,))[1] for _=1:12];\n",
    "grid(render_combined, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run inference using this combined model on the `ys` data set and the `ys_sine` data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "traces = [do_inference(combined_model, xs, ys, 10000) for _=1:10];\n",
    "overlay(render_combined, traces)\n",
    "subplot(1, 2, 2)\n",
    "traces = [do_inference(combined_model, xs, ys_sine, 10000) for _=1:10];\n",
    "overlay(render_combined, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Exercise \n",
    "\n",
    "There is code duplication in `line_model_3` and `sine_model_3`. Refactor the model to reduce code duplication and improve the readability of the code. Re-run the experiment above and confirm that the results are qualitatively the same. You may need to write a new rendering function. Try to avoid introducing code duplication between the model and the rendering code.\n",
    "\n",
    "Hint: To avoid introducing code duplication between the model and the rendering code, use the return value of the generative function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function line_model_refactored()\n",
    "    slope = @addr(normal(0, 1), :slope)\n",
    "    intercept = @addr(normal(0, 2), :intercept)\n",
    "    return (x) -> slope * x + intercept\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function sine_model_refactored()\n",
    "    period = @addr(gamma(5, 1), :period)\n",
    "    amplitude = @addr(gamma(1, 1), :amp)\n",
    "    phase = @addr(uniform(0, 2*pi), :phase)\n",
    "    return (x) -> amplitude * sin(x * (2 * pi / period) + phase)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function combined_model_refactored(xs::Vector{Float64})\n",
    "    if @addr(bernoulli(0.5), :is_line)\n",
    "        mean_fn = @splice(line_model_refactored())\n",
    "    else\n",
    "        mean_fn = @splice(sine_model_refactored())\n",
    "    end\n",
    "    noise = @addr(gamma(1, 1), :noise)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(mean_fn(x), noise), (:y, i))\n",
    "    end\n",
    "    return mean_fn;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function render_either_refactored(trace; show_data=true)\n",
    "    xs = get_args(trace)[1]\n",
    "    mean_fn = get_retval(trace)\n",
    "    assmt = get_assmt(trace)\n",
    "    if show_data\n",
    "        ys = [assmt[(:y, i)] for i=1:length(xs)]\n",
    "        scatter(xs, ys, c=\"black\")\n",
    "    end\n",
    "    xmin = minimum(xs)\n",
    "    xmax = maximum(xs)\n",
    "    test_xs = collect(range(-5, stop=5, length=100))\n",
    "    plot(test_xs, map(mean_fn, test_xs), color=\"black\", alpha=0.5)\n",
    "    ax = gca()\n",
    "    ax[:set_xlim]((xmin, xmax))\n",
    "    ax[:set_ylim]((xmin, xmax))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "traces = [do_inference(combined_model, xs, ys, 10000) for _=1:10];\n",
    "overlay(render_combined, traces)\n",
    "subplot(1, 2, 2)\n",
    "traces = [do_inference(combined_model, xs, ys_sine, 10000) for _=1:10];\n",
    "overlay(render_combined, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Construct a data set for which it is ambiguous whether the line or sine wave model is best. Visualize the inferred traces usingn `render_either` to illustrate the ambiguity. Write a program that takes the data set and returns an estimate of the posterior probability that the data was generated by the sine wave model, and run it on your data set.\n",
    "\n",
    "Hint: To estimate the posterior probability that the data was generated by the sine wave model, run the inference program many times to compute a large number of traces, and then compute the fraction of those traces in which `:is_line` is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys_ambig = 3 * sin.(0.5 * xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(3,3))\n",
    "traces = [do_inference(combined_model, xs, ys_ambig, 10000) for _=1:10];\n",
    "overlay(render_combined, traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function estimate_prob_sine(xs, ys)\n",
    "    m = 20\n",
    "    traces = [do_inference(combined_model, xs, ys, 10000) for _=1:m];\n",
    "    num_sine = sum(map((t) -> !get_assmt(t)[:is_line], traces))\n",
    "    return num_sine / m\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(estimate_prob_sine(xs, ys_ambig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(estimate_prob_sine(xs, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(estimate_prob_sine(xs, ys_sine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modeling with an infinite discrete hypothesis space  <a name=\"infinite-space\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gen's built-in modeling language can be used to express models that include more complex explanations for data that from hypothesis spaces that include an infinite set of possible discrete combinatorial structures. This section walks you through development of a model of data that does not a-priori specify an upper bound on the complexity model, but instead infers the complexity of the model as well as the parameters. This is a simple example of a *Bayesian nonparametric* model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider two data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs_dense = collect(range(-5, stop=5, length=50))\n",
    "ys_simple = fill(1., length(xs_dense)) .+ randn(length(xs_dense)) * 0.1\n",
    "ys_complex = [Int(floor(abs(x/3))) % 2 == 0 ? 2 : 0 for x in xs_dense] .+ randn(length(xs_dense)) * 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "subplot(1, 2, 1)\n",
    "scatter(xs_dense, ys_simple, color=\"black\", s=10)\n",
    "gca()[:set_ylim]((-1, 3))\n",
    "subplot(1, 2, 2)\n",
    "scatter(xs_dense, ys_complex, color=\"black\", s=10);\n",
    "gca()[:set_ylim]((-1, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set on the left appears to be best explained as a contant function with some noise. The data set on the right appears to include four changepoints, with a constant function in between the changepoints. We want a model that does not a-priori choose the number of changepoints in the data. To do this, we will recursively partition the interval into regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct Interval\n",
    "    l::Float64\n",
    "    u::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract type Node end\n",
    "    \n",
    "struct InternalNode <: Node\n",
    "    left::Node\n",
    "    right::Node\n",
    "    interval::Interval\n",
    "end\n",
    "\n",
    "struct LeafNode <: Node\n",
    "    value::Float64\n",
    "    interval::Interval\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function generate_segments(l::Float64, u::Float64)\n",
    "    interval = Interval(l, u)\n",
    "    if @addr(bernoulli(0.7), :isleaf)\n",
    "        value = @addr(normal(0, 1), :value)\n",
    "        return LeafNode(value, interval)\n",
    "    else\n",
    "        frac = @addr(beta(2, 2), :frac)\n",
    "        mid  = l + (u - l) * frac\n",
    "        left = @addr(generate_segments(l, mid), :left)\n",
    "        right = @addr(generate_segments(mid, u), :right)\n",
    "        return InternalNode(left, right, interval)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function render_node(node::LeafNode)\n",
    "    plot([node.interval.l, node.interval.u], [node.value, node.value])\n",
    "end\n",
    "\n",
    "function render_node(node::InternalNode)\n",
    "    render_node(node.left)\n",
    "    render_node(node.right)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function render_segments_trace(trace)\n",
    "    node = get_retval(trace)\n",
    "    render_node(node)\n",
    "    ax = gca()\n",
    "    ax[:set_xlim]((0, 1))\n",
    "    ax[:set_ylim]((-3, 3))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate 12 traces from this function and visualize them below. We plot the piecewise constant function that was sampled by each run of the generative function. Different constant segments are shown in different colors. Run the cell a few times to get a better sense of the distribution on functions that is represented by the generative function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [initialize(generate_segments, (0., 1.))[1] for i=1:12]\n",
    "grid(render_segments_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generative function that generates an unknown partition into segments with values, we write a model that adds noise to the resulting constant functions to generate a data set of y-coordinates. The noise level will be a random choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function get_value_at(x::Float64, node::LeafNode)\n",
    "    @assert x >= node.interval.l && x <= node.interval.u\n",
    "    return node.value\n",
    "end\n",
    "\n",
    "function get_value_at(x::Float64, node::InternalNode)\n",
    "    @assert x >= node.interval.l && x <= node.interval.u\n",
    "    if x <= node.left.interval.u\n",
    "        get_value_at(x, node.left)\n",
    "    else\n",
    "        get_value_at(x, node.right)\n",
    "    end\n",
    "end\n",
    "\n",
    "@gen function changepoint_model(xs::Vector{Float64})\n",
    "    node = @addr(generate_segments(minimum(xs), maximum(xs)), :tree)\n",
    "    noise = @addr(gamma(1, 1), :noise)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(get_value_at(x, node), noise), (:y, i))\n",
    "    end\n",
    "    return node\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a visualization for `changepoint_model` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function render_cp_model_trace(trace; show_data=true)\n",
    "    xs = get_args(trace)[1]\n",
    "    node = get_retval(trace)\n",
    "    render_node(node)\n",
    "    assmt = get_assmt(trace)\n",
    "    if show_data\n",
    "        ys = [assmt[(:y, i)] for i=1:length(xs)]\n",
    "        scatter(xs, ys, c=\"black\")\n",
    "    end\n",
    "    ax = gca()\n",
    "    ax[:set_xlim]((minimum(xs), maximum(xs)))\n",
    "    ax[:set_ylim]((-3, 3))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate some simulated data sets and visualize them on top of the underlying piecewise constant function from which they were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [initialize(changepoint_model, (xs_dense,))[1] for i=1:12]\n",
    "grid(render_cp_model_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the amount of variability around the piecewise constant mean function differs from trace to trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform inference for the simple data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [do_inference(changepoint_model, xs_dense, ys_simple, 10000) for _=1:12];\n",
    "grid(render_cp_model_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we inferred that the mean function that explains the data is a constant with very high probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inference about the complex data set, we use more computation. You can experiment with different amounts of computation to see how the quality of the inferences degrade with less computation. Note that we are using a very simple generic inference algorithm in this tutorial. In later tutorials, we will learn how to write more efficient algorithms, so that accurate results can be obtained with significantly less amount of computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traces = [do_inference(changepoint_model, xs_dense, ys_complex, 100000) for _=1:12];\n",
    "grid(render_cp_model_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Exercise\n",
    "Write a function that plots the histogram of the probability distribution on the number of changepoints.\n",
    "Show the results for the `ys_simple` and `ys_complex` data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### Exercise\n",
    "Write a new version of `changepoint_model` that uses `@splice` to make the recursive calls instead of `@addr`.\n",
    "\n",
    "Hint: Recall that addresses can be arbitrary values, not just symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function generate_segments_splice(idx::Int, l::Float64, u::Float64)\n",
    "    interval = Interval(l, u)\n",
    "    if @addr(bernoulli(0.7), (idx, :isleaf))\n",
    "        value = @addr(normal(0, 1), (idx, :value))\n",
    "        return LeafNode(value, interval)\n",
    "    else\n",
    "        frac = @addr(beta(2, 2), (idx, :frac))\n",
    "        mid  = l + (u - l) * frac\n",
    "        left = @splice(generate_segments_splice(idx * 2, l, mid))\n",
    "        right = @splice(generate_segments_splice(idx * 2 + 1, mid, u))\n",
    "        return InternalNode(left, right, interval)\n",
    "    end\n",
    "end;\n",
    "\n",
    "@gen function changepoint_model_splice(xs::Vector{Float64})\n",
    "    node = @addr(generate_segments_splice(1, minimum(xs), maximum(xs)), :tree)\n",
    "    noise = @addr(gamma(1, 1), :noise)\n",
    "    for (i, x) in enumerate(xs)\n",
    "        @addr(normal(get_value_at(x, node), noise), (:y, i))\n",
    "    end\n",
    "    return node\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [do_inference(changepoint_model_splice, xs_dense, ys_complex, 100000) for _=1:12];\n",
    "grid(render_cp_model_trace, traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with black box code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will implement an inference program that infers the probable destination of an autonomous agent from its observed motion in a two-dimensional environment with obstacles. The model witll include (i) a prior distribution on the destination of the agent, and (ii) an algorithmic model for how the agent plans its movement based on its destination, (iii) a statistical model of the noise in our measurements of the agent's motion. This model illustrates that arbitrary code (in this case, the planning algorithm) and custom data types can be included in Gen models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have provided some of the basic geometric primitives in the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include(\"geometric_primitives.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file defines two-dimensional `Point` data type with fields `x` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = Point(1.0, 2.0)\n",
    "println(point.x)\n",
    "println(point.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file defines a method that computes the distance between two points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist(Point(1.0, 1.0), Point(0.0, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file also defines an `Obstacle` data type, which represents a polygonal obstacle in a two-dimensional scene, that is constructed from a list of vertices. Here, we construct a square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obstacle = Obstacle([Point(0.0, 0.0), Point(1.0, 0.0), Point(0.0, 1.0), Point(1.0, 1.0)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file also defines a method to test whether an obstacle intersects with a line segment, which is defined by a start point and an end point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(obstacle_intersects_line_segment(obstacle, Point(-1.0, 0.5), Point(2.0, 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(obstacle_intersects_line_segment(obstacle, Point(-1.0, 1.5), Point(2.0, 1.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these geometric primitives, we define a data type to represent the two-dimensional scene. The scene spans a rectangle of on the two-dimensional x-y plane, and contains a list of obstacles. Each obstacle is a polygon defined by a list of vertex points. We also define a method to compute whether a given line is obstructed by any obstacles in the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct Scene\n",
    "    xmin::Float64\n",
    "    xmax::Float64\n",
    "    ymin::Float64\n",
    "    ymax::Float64\n",
    "    obstacles::Vector{Obstacle}\n",
    "end\n",
    "\n",
    "Scene(xmin, xmax, ymin, ymax) = Scene(xmin, xmax, ymin, ymax, Obstacle[])\n",
    "\n",
    "add_obstacle!(scene, obstacle::Obstacle) = push!(scene.obstacles, obstacle)\n",
    "\n",
    "function line_is_obstructed(scene::Scene, a1::Point, a2::Point)\n",
    "    for obstacle in scene.obstacles\n",
    "        if obstacle_intersects_line_segment(obstacle, a1, a2)\n",
    "            return true\n",
    "        end\n",
    "    end\n",
    "    false\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write some methods that allow us to concisely construct walls (line-shaped obstacles that are either vertically or horizontally oriented), and square-shaped obstacles (representing trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function make_wall(vertical::Bool, start::Point, length::Float64, thickness::Float64)\n",
    "    vertices = Vector{Point}(undef, 4)\n",
    "    vertices[1] = start\n",
    "    dx = vertical ? thickness : length\n",
    "    dy = vertical ? length : thickness\n",
    "    vertices[2] = Point(start.x + dx, start.y)\n",
    "    vertices[3] = Point(start.x + dx, start.y + dy) \n",
    "    vertices[4] = Point(start.x, start.y + dy)\n",
    "    Obstacle(vertices)\n",
    "end \n",
    "\n",
    "function make_tree(center::Point, size::Float64)\n",
    "    vertices = Vector{Point}(undef, 4)\n",
    "    vertices[1] = Point(center.x - size/2, center.y - size/2)\n",
    "    vertices[2] = Point(center.x + size/2, center.y - size/2)\n",
    "    vertices[3] = Point(center.x + size/2, center.y + size/2)\n",
    "    vertices[4] = Point(center.x - size/2, center.y + size/2)\n",
    "    Obstacle(vertices)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now construct a scene value that we will use in the rest of the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene = Scene(0, 1, 0, 1)\n",
    "add_obstacle!(scene, make_tree(Point(0.30, 0.20), 0.1))\n",
    "add_obstacle!(scene, make_tree(Point(0.83, 0.80), 0.1))\n",
    "add_obstacle!(scene, make_tree(Point(0.80, 0.40), 0.1))\n",
    "horizontal = false\n",
    "vertical = true\n",
    "wall_thickness = 0.02\n",
    "add_obstacle!(scene, make_wall(horizontal, Point(0.20, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(vertical, Point(0.60, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(horizontal, Point(0.60 - 0.15, 0.80), 0.15 + wall_thickness, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(horizontal, Point(0.20, 0.80), 0.15, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(vertical, Point(0.20, 0.40), 0.40, wall_thickness));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the scene below, using a custom visualization written using [GenViz](https://github.com/probcomp/GenViz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use GenViz, we first start a GenViz server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using GenViz\n",
    "server = VizServer(8000)\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info = Dict(\"scene\" => scene)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a simple planning algorithm based on the rapidly exploring random tree (RRT) algorithm [2]. The planning algorithm will take as input (i) the scene, (ii) the start point, and (iii) the destination point, and will produce a sequence of points that starts with the start point and ends with the destination point, such the line of sight between each consecutive point does not intersect any obstacles, or return failure if no path could be found.\n",
    "\n",
    "[2] Rapidly-exploring random trees: A new tool for path planning. S. M. LaValle. TR 98-11, Computer Science Dept., Iowa State University, October 1998,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load an implementation of the RRT algorithm from the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include(\"rrt.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file defines a method `generate_rrt` that takes a scene, a starting point, and algorithm parameters, and returns an `RRT` value, which represents a tree rooted at the starting point that fills the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = Point(0.1, 0.1)\n",
    "tree = generate_rrt(scene, start, 300, 3.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We visualize the resulting tree on top of the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info = Dict(\"start\"=> start, \"scene\" => scene, \"tree_edges\" => get_edges(tree))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a RRT, and a destination point, we can find a path from the root of the RRT to the destination point, by finding a node on the tree that has a clear line-of-sight to the destination node, and is also as close as possible to the destination node. We then walk back from this node along the edges of the tree to the route to construct the path. If there is no node on the tree with a clear line-of-sight to the destination, we return the value `nothing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct Path\n",
    "    points::Vector{Point}\n",
    "end\n",
    "\n",
    "function get_path_to_dest(tree::RRT, destination::Point)\n",
    "    \n",
    "    # find a node in the tree with a clear line-of-sight to the destination\n",
    "    best_node = tree.nodes[1]\n",
    "    min_cost = Inf\n",
    "    path_found = false\n",
    "    for node in tree.nodes\n",
    "        clear_path = !line_is_obstructed(scene, node.conf, destination)\n",
    "        cost = node.dist_from_start + (clear_path ? dist(node.conf, destination) : Inf)\n",
    "        if cost < min_cost\n",
    "            path_found = true\n",
    "            best_node = node\n",
    "            min_cost = cost\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if path_found\n",
    "        \n",
    "        # walk from the best node to the root of the tree to construct the path\n",
    "        points = Point[destination]\n",
    "        node = best_node\n",
    "        while node.parent != nothing\n",
    "            push!(points, node.conf)\n",
    "            node = node.parent\n",
    "        end\n",
    "        push!(points, root(tree).conf)\n",
    "        Path(reverse(points))\n",
    "    else\n",
    "        \n",
    "        # return nothing if no path was found\n",
    "        nothing\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize an example path below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function get_edges(path::Path)\n",
    "    edges = Tuple{Point,Point}[]\n",
    "    for i=1:length(path.points)-1\n",
    "        push!(edges, (path.points[i], path.points[i+1]))\n",
    "    end\n",
    "    edges\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest = Point(0.5, 0.5)\n",
    "path = get_path_to_dest(tree, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info = Dict(\"start\"=> start, \"dest\" => dest, \"scene\" => scene,\n",
    "    \"tree_edges\" => get_edges(tree), \"path_edges\" => get_edges(path))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths along the tree that are generated by the RRT algorithm are generally not very direct. We want our agent to take fairly direct paths from its starting location to the destination. Therefore, we use the following path-refinement procedure to optimize the path points to shorten the length of the path while still avoiding obstruction by obstacles. You don't need to worry about the details of this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function refine_path(scene::Scene, original::Path, iters::Int, std::Float64)\n",
    "    new_points = copy(original.points)\n",
    "    num_interior_points = length(original.points) -2\n",
    "    if num_interior_points == 0\n",
    "        return original\n",
    "    end\n",
    "    for i=1:iters\n",
    "        \n",
    "        # propose an adjustment to one of the interior points on the path (not the first or last point)\n",
    "        point_idx = 2 + (i % num_interior_points)\n",
    "        prev_point = new_points[point_idx-1]\n",
    "        point = new_points[point_idx]\n",
    "        next_point = new_points[point_idx+1]\n",
    "        adjusted_point = Point(point.x + randn() * std, point.y + randn() * std)\n",
    "        \n",
    "        # check if the new path is obstructed by obstacles\n",
    "        ok_backward = !line_is_obstructed(scene, prev_point, adjusted_point)\n",
    "        ok_forward = !line_is_obstructed(scene, adjusted_point, next_point)\n",
    "        \n",
    "        # accept the adjustment if it is not obstructed by obstacles and it reduces the length of the path\n",
    "        if ok_backward && ok_forward\n",
    "            new_dist = dist(prev_point, adjusted_point) + dist(adjusted_point, next_point)\n",
    "            cur_dist = dist(prev_point, point) + dist(point, next_point)\n",
    "            if new_dist < cur_dist\n",
    "                new_points[point_idx] = adjusted_point\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    Path(new_points)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = refine_path(scene, path, 2000, 1.)\n",
    "info = Dict(\"start\"=> start, \"dest\" => dest, \"scene\" => scene,\n",
    "    \"tree_edges\" => get_edges(tree), \"path_edges\" => get_edges(path))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we combine each of the steps we just defined into a path-planning function. If a path could not be found, we return the value `nothing`. Otherwise, we return a `Path` value The path-planning function has parameters for how to grow the RRT (`rrt_iters` and `rrt_dt`) and how to perform the refinement (`refine_iters` and `refine_std`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct PlannerParams\n",
    "    rrt_iters::Int\n",
    "    rrt_dt::Float64\n",
    "    refine_iters::Int\n",
    "    refine_std::Float64\n",
    "end\n",
    "\n",
    "function plan_path(start::Point, dest::Point, scene::Scene, params::PlannerParams)\n",
    "    \n",
    "    # Generate a rapidly exploring random tree\n",
    "    tree = generate_rrt(scene, start, params.rrt_iters, params.rrt_dt)\n",
    "\n",
    "    # Find a route from the root of the tree to a node on the tree that has a line-of-sight to the destination\n",
    "    maybe_path = get_path_to_dest(tree, dest)\n",
    "    \n",
    "    if maybe_path == nothing\n",
    "        \n",
    "        # No route found\n",
    "        return (nothing, tree)\n",
    "    else\n",
    "        \n",
    "        # Route found\n",
    "        path = something(maybe_path)\n",
    "        refined_path = refine_path(scene, maybe_path, params.refine_iters, params.refine_std)\n",
    "        return (refined_path, tree)\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the end-to-end path planning procedure. Run the cell below a few times to get a sense for the variability in the path planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(path, tree) = plan_path(start, dest, scene, PlannerParams(300, 3.0, 2000, 1.))\n",
    "info = Dict(\"start\"=> start, \"dest\" => dest, \"scene\" => scene,\n",
    "    \"tree_edges\" => get_edges(tree), \"path_edges\" => get_edges(path))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a model for how the agent moves along its path.\n",
    "We will assume that the agent moves along its path a constant speed. The cell below defines a method that computes the locations of the agent at a set of timepoints, given the path and the speed of the agent. You don't need to worry about the details of this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_distances_from_start(path::Path)\n",
    "    distances_from_start = Vector{Float64}(undef, length(path.points))\n",
    "    distances_from_start[1] = 0.0\n",
    "    for i=2:length(path.points)\n",
    "        distances_from_start[i] = distances_from_start[i-1] + dist(path.points[i-1], path.points[i])\n",
    "    end\n",
    "    return distances_from_start\n",
    "end\n",
    "\n",
    "function walk_path(path::Path, speed::Float64, dt::Float64, num_ticks::Int)\n",
    "    distances_from_start = compute_distances_from_start(path)\n",
    "    locations = Vector{Point}(undef, num_ticks)\n",
    "    locations[1] = path.points[1]\n",
    "    t = 0.\n",
    "    for time_idx=1:num_ticks\n",
    "        desired_distance = t * speed\n",
    "        used_up_time = false\n",
    "        # NOTE: can be improved (iterate through path points along with times)\n",
    "        for i=2:length(path.points)\n",
    "            prev = path.points[i-1]\n",
    "            cur = path.points[i]\n",
    "            dist_to_prev = dist(prev, cur)\n",
    "            if distances_from_start[i] >= desired_distance\n",
    "                # we overshot, the location is between i-1 and i\n",
    "                overshoot = distances_from_start[i] - desired_distance\n",
    "                @assert overshoot <= dist_to_prev\n",
    "                past_prev = dist_to_prev - overshoot\n",
    "                frac = past_prev / dist_to_prev\n",
    "                locations[time_idx] = Point(prev.x * (1. - frac) + cur.x * frac,\n",
    "                                     prev.y * (1. - frac) + cur.y * frac)\n",
    "                used_up_time = true\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        if !used_up_time\n",
    "            # sit at the goal indefinitely\n",
    "            locations[time_idx] = path.points[end]\n",
    "        end\n",
    "        t += dt\n",
    "    end\n",
    "    locations\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can write a generative function that models the behavior of an autonomous agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@gen function model(scene::Scene, dt::Float64, num_ticks::Int)\n",
    "\n",
    "    # sample the start point of the agent from the prior\n",
    "    start_x = @addr(uniform(0, 1), :start_x)\n",
    "    start_y = @addr(uniform(0, 1), :start_y)\n",
    "    start = Point(start_x, start_y)\n",
    "\n",
    "    # sample the destination point of the agent from the prior\n",
    "    dest_x = @addr(uniform(0, 1), :dest_x)\n",
    "    dest_y = @addr(uniform(0, 1), :dest_y)\n",
    "    dest = Point(dest_x, dest_y)\n",
    "\n",
    "    # plan a path that avoids obstacles in the scene\n",
    "    (maybe_path, _) = plan_path(start, dest, scene, PlannerParams(300, 3.0, 2000, 1.))\n",
    "    \n",
    "    # sample the speed from the prior\n",
    "    speed = @addr(uniform(0, 1), :speed)\n",
    "\n",
    "    if maybe_path == nothing\n",
    "        \n",
    "        # path planning failed, assume the agent stays as the start location indefinitely\n",
    "        locations = fill(start, num_ticks)\n",
    "    else\n",
    "        \n",
    "        # path planning succeeded, move along the path at constant speed\n",
    "        path = something(maybe_path)\n",
    "        locations = walk_path(path, speed, dt, num_ticks)\n",
    "    end\n",
    "\n",
    "    # generate noisy measurements\n",
    "    noise = 0.01\n",
    "    measurements = Vector{Point}(undef, num_ticks)\n",
    "    for (i, point) in enumerate(locations)\n",
    "        x = @addr(normal(point.x, noise), :meas => i => :x)\n",
    "        y = @addr(normal(point.y, noise), :meas => i => :y)\n",
    "        measurements[i] = Point(x, y)\n",
    "    end\n",
    "\n",
    "    (start, dest, speed, noise, maybe_path, locations, measurements)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a time step of `dt = 0.1` and we will assume that 10 measurements are taken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const dt = 0.1\n",
    "const num_ticks = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform traced executions the generative function using Gen's `initialize` method. Here, we obtain a traced execution, then obtain the assignment to random choices made during the execution, and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trace, _) = initialize(model, (scene, dt, num_ticks));\n",
    "assmt = get_assmt(trace)\n",
    "println(assmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explore the assumptions of the model by sampling many traces from the generative function and visualizing them. We have created a visualization specialized for this generative function for use with the `GenViz` package, in the directory `grid-viz/dist`. We have also defined a `trace_to_dict` method to convert the trace into a value that can be easily serialized into a JSON string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function trace_to_dict(trace)\n",
    "    args = get_args(trace)\n",
    "    (scene, dt, num_ticks) = args\n",
    "\n",
    "    retval = get_retval(trace)\n",
    "    (start, dest, speed, noise, maybe_path, locations, measurements) = retval\n",
    "\n",
    "    d = Dict()\n",
    "\n",
    "    # scene (the obstacles)\n",
    "    d[\"scene\"] = scene\n",
    "\n",
    "    # the path\n",
    "    if maybe_path != nothing\n",
    "        d[\"path\"] = maybe_path.points\n",
    "    else\n",
    "        d[\"path\"] = []\n",
    "    end\n",
    "\n",
    "    # start and destination location\n",
    "    d[\"start\"] = start\n",
    "    d[\"dest\"] = dest\n",
    "\n",
    "    # observed points\n",
    "    d[\"measurements\"] = measurements\n",
    "\n",
    "    d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Random\n",
    "Random.seed!(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz = Viz(server, joinpath(@__DIR__, \"grid-viz/dist\"), [])\n",
    "constraints = DynamicAssignment()\n",
    "constraints[:start_x] = 0.1\n",
    "constraints[:start_y] = 0.1\n",
    "for i=1:12\n",
    "    (trace, _) = initialize(model, (scene, dt, num_ticks), constraints)\n",
    "    putTrace!(viz, i, trace_to_dict(trace))\n",
    "end\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this visualziation, the start location is represented by a blue dot, and the destination is represented by a red dot. The measured coordinates at each time point are represented by black dots. The path, if path planning was succesfull, is shown as a gray line fro the start point to the destination point. Notice that the speed of the agent is different in each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write a simple algorithm for inferring the destination of an agent given (i) the scene, (ii) the start location of the agent, and (iii) a sequence of measured locations of the agent for each tick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = Point(0.1, 0.1)\n",
    "\n",
    "measurements = [\n",
    "    Point(0.0980245, 0.104775),\n",
    "    Point(0.113734, 0.150773),\n",
    "    Point(0.100412, 0.195499),\n",
    "    Point(0.114794, 0.237386),\n",
    "    Point(0.0957668, 0.277711),\n",
    "    Point(0.140181, 0.31304),\n",
    "    Point(0.124384, 0.356242),\n",
    "    Point(0.122272, 0.414463),\n",
    "    Point(0.124597, 0.462056),\n",
    "    Point(0.126227, 0.498338)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We visualize the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(path, tree) = plan_path(start, dest, scene, PlannerParams(300, 3.0, 2000, 1.))\n",
    "info = Dict(\"start\" => start, \"scene\" => scene, \"measurements\" => measurements)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function do_inference(scene::Scene, dt::Float64, num_ticks::Int, start::Point,\n",
    "                      measurements::Vector{Point}, num_particles::Int)\n",
    "    \n",
    "    # construct observations assignment\n",
    "    observations = DynamicAssignment()\n",
    "    observations[:start_x] = start.x\n",
    "    observations[:start_y] = start.y\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => i => :x] = m.x\n",
    "        observations[:meas => i => :y] = m.y\n",
    "    end\n",
    "    \n",
    "    # use importance sampling with resampling to obtain an inferred trace\n",
    "    (trace, _) = importance_resampling(model, (scene, dt, num_ticks), observations, num_particles)\n",
    "    \n",
    "    trace\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we run this algorithm 1000 times, using 50 particles for each run, and visualize the inferred destinations. The inferred destinations should appear as red dots on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info = Dict(\"measurements\" => measurements, \"scene\" => scene, \"start\" => start)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "openInNotebook(viz)\n",
    "sleep(5)\n",
    "for i=1:1000\n",
    "    trace = do_inference(scene, dt, num_ticks, start, measurements, 50)\n",
    "    putTrace!(viz, i, trace_to_dict(trace))\n",
    "end\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Exercise\n",
    "\n",
    "Write an inference program that infers both the agent's destination and whether or not the walled square is present in the scene or not. Show resut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
